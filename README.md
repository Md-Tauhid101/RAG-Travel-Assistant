# ğŸŒ RAG Travel Assistant (RAG + Knowledge Graph + Semantic Cache)

An intelligent **AI travel assistant** that combines **Vector Search (Pinecone)**, **Graph Reasoning (Neo4j)**, and **Semantic Caching (Redis)** to deliver context-aware, fast, and accurate travel recommendations.

---

## ğŸš€ Overview

This project implements a **hybrid retrieval pipeline** that merges **semantic similarity** from a vector database and **relational knowledge** from a graph database.  
It intelligently caches previous user interactions to **reduce cost and latency**, while ensuring **contextual reasoning** and **dynamic graph traversal** for accurate answers.

---

## ğŸ§  Key Features

- **Hybrid Retrieval (Vector + Graph):**  
  Retrieves semantically relevant documents from **Pinecone** and relationship-driven facts from **Neo4j**.

- **Semantic Caching Layer (Redis):**  
  Uses a semantic cache to avoid redundant vector or LLM queries for similar user inputs.

- **Asynchronous Execution:**  
  Both retrievals (Pinecone + Neo4j) are executed concurrently for better performance.

- **Context Summarization:**  
  Summarizes the combined vector and graph context before prompting the LLM.

- **Dynamic Prompt Construction:**  
  Builds structured, context-rich prompts for more relevant LLM answers.

---

## âš™ï¸ System Architecture

```text
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        User Query           â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     Semantic Cache (Redis) â”‚
                â”‚  - Checks if similar query â”‚
                â”‚    exists in cache         â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ (cache miss)
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                            â”‚                            â”‚
        â–¼                            â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector DB         â”‚        â”‚ Graph DB         â”‚         â”‚ Asynchronous Execution   â”‚
â”‚ (Pinecone)        â”‚        â”‚ (Neo4j)          â”‚         â”‚ (asyncio + to_thread)    â”‚
â”‚ Retrieves seman-  â”‚        â”‚ Fetches relation â”‚         â”‚ Runs both tasks in       â”‚
â”‚ tic matches       â”‚        â”‚ facts between    â”‚         â”‚ parallel threads         â”‚
â”‚                   â”‚        â”‚ nodes            â”‚         â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                             â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Context Summarization     â”‚
               â”‚  Merges vector + graph data â”‚
               â”‚  into a single summary      â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚     LLM Prompt Builder      â”‚
               â”‚  Constructs prompt with:    â”‚
               â”‚  - Semantic summary         â”‚
               â”‚  - Graph context            â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚         LLM (OpenAI)       â”‚
               â”‚  Generates answer based on â”‚
               â”‚  summarized hybrid context â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Cache Result in Redis    â”‚
               â”‚  for future retrievals     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚        Final Answer        â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Setup & Installation

1ï¸âƒ£ Clone the Repository
```python
    git clone https://github.com/Md-Tauhid101/RAG-Travel-Assistant.git
    cd RAG-Travel-Assistant
```

## 2ï¸âƒ£ Create a Virtual Environment
```python
    python -m venv env
    source env/bin/activate   # On Windows: env\Scripts\activate
```

## 3ï¸âƒ£ Install Dependencies
```python
    pip install -r requirements.txt
```

## 4ï¸âƒ£ Environment Variables
- fill the credentials in the config:
```python
    OPENAI_API_KEY=your_openai_api_key
    PINECONE_API_KEY=your_pinecone_api_key
    PINECONE_ENVIRONMENT=your_pinecone_env
    NEO4J_URI=bolt://localhost:7687
    NEO4J_USER=neo4j
    NEO4J_PASSWORD=your_password
    REDIS_URL=redis://localhost:6379
```

## ğŸ§  Usage
### Task 1 â€“ Setup & Data Upload
```python
    python pinecone_upload.py
```

### Task 2 â€“ Create Graph Database 
```python
    python load_to_neo4j.py
```

### Task 2 â€“ Hybrid Chat
```python
    python hybrid_chat.py
```

## Enhancements

âœ… Caching: Redis-based semantic cache to skip repetitive queries.

âœ… Async Retrieval: Parallel vector + graph fetching via asyncio.gather().

âœ… Context Summarization: Summarizes top nodes before prompt generation.

âœ… Prompt Improvement: Designed concise, context-grounded LLM prompts.

## ğŸ§  Key Learnings

- Built and debugged hybrid retrieval between vector & graph databases.
- Implemented async design for parallel querying to minimize latency.
- Designed structured prompt templates for LLM-based itinerary generation.
- Learned failure modes (vectorâ€“graph desync, latency spikes, token overflow).

## ğŸ§° Future Improvements

- Add FastAPI-based web interface
- Integrate LangChain or LlamaIndex for modular retrieval pipeline
- Add feedback-based reranking
- Experiment with local LLMs for cost reduction
